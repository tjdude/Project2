{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPPjuJwE03RNOmix7KMkikn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["라이브러리 임포트"],"metadata":{"id":"q2quCNUaOInM"}},{"cell_type":"code","source":["import cv2\n","import tensorflow.lite as tflite\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import base64\n","from sklearn.cluster import KMeans\n","from flask import Flask, request, jsonify, render_template\n","from PIL import Image"],"metadata":{"id":"QNj7eFcBOLTO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["모델 및 클래스 설정\n","- 두피 상태를 분류하기 위한 클래스 목록\n","- 모발 개수를 탐지하기 위한 클래스 목록"],"metadata":{"id":"J_4W7oAlOp8W"}},{"cell_type":"code","source":["app = Flask(__name__)\n","\n","# 클래스 이름 설정\n","classification_names = ['normal', 'mild', 'moderate', 'severe']\n","detection_names = ['1hair', '2hair', '3hair', '4hair']\n","\n","# 모델 로드\n","classification_model_path = 'hlcM_torchQ16.tflite'\n","detection_model_path = 'yolo300_float32.tflite'\n","\n","classification_interpreter = tflite.Interpreter(model_path=classification_model_path)\n","classification_interpreter.allocate_tensors()\n","class_input_details = classification_interpreter.get_input_details()\n","class_output_details = classification_interpreter.get_output_details()\n","\n","detection_interpreter = tflite.Interpreter(model_path=detection_model_path)\n","detection_interpreter.allocate_tensors()\n","detect_input_details = detection_interpreter.get_input_details()\n","detect_output_details = detection_interpreter.get_output_details()\n","\n","# YOLO 모델의 입력 이미지 크기 shape에서 추출\n","detect_img_height = detect_input_details[0]['shape'][1]\n","detect_img_width = detect_input_details[0]['shape'][2]\n"],"metadata":{"id":"-nYzy8E6QPYS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["이미지 처리 함수 process_image\n","- 분류 모델 입력에 맞게 이미지 전처리\n","- TF-Lite 분류 모델 추론 수행\n","- 예측 결과를 통해 두피 상태 라벨 반환"],"metadata":{"id":"z7-GEDKR8OLr"}},{"cell_type":"code","source":["def process_image(image):\n","    if not isinstance(image, np.ndarray):\n","        print(f\"오류: 지원되지 않는 이미지 형식 ({type(image)})\")\n","        return None\n","\n","    #BGR 이미지 RGB로 변환\n","    original_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    img_h, img_w, _ = original_image.shape\n","\n","    # 두피 상태 분류\n","    class_image = cv2.resize(image, (224, 224))\n","    class_image = np.array(class_image, dtype=np.float32)\n","    class_image = np.expand_dims(class_image, axis=0)\n","\n","    classification_interpreter.set_tensor(class_input_details[0]['index'], class_image)\n","    classification_interpreter.invoke()\n","    class_output = classification_interpreter.get_tensor(class_output_details[0]['index'])\n","    class_pred = np.argmax(class_output[0])\n","    class_label = classification_names[class_pred]"],"metadata":{"id":"qJ7IsqFkRfbC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- YOLO 모델을 사용해 입력 이미지에서 모발 개수 탐지\n","- 출력 처리\n","  - boxes_xywh : 중심 좌표 기준 박스 정보\n","  - score, classes : 클래스별 confidence 추출\n","- 최종 탐지된 결과 이미지에 바운딩 박스 및 라벨 시각화"],"metadata":{"id":"ZzsLQu8LRgNq"}},{"cell_type":"code","source":["    # 이미지 전처리\n","    detect_image = cv2.resize(image, (detect_img_width, detect_img_height))\n","    detect_image = np.array(detect_image, dtype=np.float32) / 255.0\n","    detect_image = np.expand_dims(detect_image, axis=0)\n","\n","    # YOLO 모델\n","    detection_interpreter.set_tensor(detect_input_details[0]['index'], detect_image)\n","    detection_interpreter.invoke()\n","    output = detection_interpreter.get_tensor(detect_output_details[0]['index'])[0].T\n","\n","    if output.shape[1] == 8:\n","        boxes_xywh = output[:, :4]\n","        scores = np.max(output[:, 4:], axis=1)\n","        classes = np.argmax(output[:, 4:], axis=1)\n","    else:\n","        print(\"오류: YOLO 모델 출력 형식 확인 필요.\")\n","        return None\n","\n","    threshold = 0.2\n","    iou_threshold = 0.4\n","\n","    boxes, confidences, class_ids = [], [], []\n","    for i, s in enumerate(scores):\n","        if s > threshold:\n","            x_center, y_center, width, height = boxes_xywh[i] * [img_w, img_h, img_w, img_h]\n","            x1, y1, x2, y2 = int(x_center - width / 2), int(y_center - height / 2), int(x_center + width / 2), int(\n","                y_center + height / 2)\n","            boxes.append([x1, y1, x2, y2])\n","            confidences.append(float(s))\n","            class_ids.append(classes[i])\n","\n","    # 이미지에 결과 시각화 표시\n","    indices = cv2.dnn.NMSBoxes(boxes, confidences, threshold, iou_threshold)\n","    if len(indices) > 0:\n","        indices = indices.flatten()\n","        for i in indices:\n","            x1, y1, x2, y2 = boxes[i]\n","            cls = class_ids[i]\n","            score = confidences[i]\n","            cv2.rectangle(original_image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n","            text = f\"{detection_names[cls]} ({score:.2f})\"\n","            cv2.putText(original_image, text, (x1, max(20, y1 - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)"],"metadata":{"id":"rrNYJpXjRmOE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["KMeans로 두피/모발 비율 산출\n","- 입력 이미지 LAB 컬러 공간으로 변환 후 2개의 군집으로 수행\n","- 두피(흰색), 머리카락(검정색)으로 픽셀값 이진화\n","- 머리카락과 두피 픽셀 수 기반으로 각각의 비율 계산"],"metadata":{"id":"EY_DxTzZRoVU"}},{"cell_type":"code","source":["    # KMeans 클러스터링\n","    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n","    pixels = lab_image.reshape((-1, 3))\n","\n","    kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n","    labels = kmeans.fit_predict(pixels)\n","    segmented_image = labels.reshape(image.shape[:2])\n","\n","    #  두피 : 흰색(255), 머리카락 : 검정색(0)\n","    if np.mean(segmented_image) > 0.5:\n","        segmented_image = 1 - segmented_image\n","\n","    segmented_image = (segmented_image * 255).astype(np.uint8)\n","\n","    # hair_ratio, scalp_ratio 계산\n","    hair_pixels = np.sum(segmented_image == 0)\n","    scalp_pixels = np.sum(segmented_image == 255)\n","    total_pixels = hair_pixels + scalp_pixels\n","\n","    hair_ratio = (hair_pixels / total_pixels) * 100 if total_pixels > 0 else 0\n","    scalp_ratio = (scalp_pixels / total_pixels) * 100 if total_pixels > 0 else 0\n","\n",""],"metadata":{"id":"WSNg7aAEA4M1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Flask에서 표시하기 위해 base64로 인코딩 후 JSON 응답으로 변환"],"metadata":{"id":"JokRrXfGBNaz"}},{"cell_type":"code","source":[" _, buffer1 = cv2.imencode(\".jpg\", cv2.cvtColor(original_image, cv2.COLOR_RGB2BGR))\n","    image_base64_1 = base64.b64encode(buffer1).decode(\"utf-8\")\n","\n","    _, buffer2 = cv2.imencode(\".jpg\", cv2.cvtColor(segmented_image, cv2.COLOR_GRAY2RGB))\n","    image_base64_2 = base64.b64encode(buffer2).decode(\"utf-8\")\n","\n","    result = {\n","        \"classification\": class_label,\n","        \"detection\": [\n","            {\"box\": boxes[i], \"confidence\": confidences[i], \"label\": detection_names[class_ids[i]]} for i in indices\n","        ],\n","        \"segmentation\": {\n","        \"hair_ratio\": round(hair_ratio, 2),\n","        \"scalp_ratio\": round(scalp_ratio, 2)},\n","        \"image1\": image_base64_1,  # 탐지 결과\n","        \"image2\": image_base64_2   # 클러스터링 결과\n","    }\n","    return result"],"metadata":{"id":"zsRiSfu0BMZz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Flask 엔드포인트\n","- upload.html에서 이미지 업로드\n","- 서버에서 이미지 분석\n","- 분석 결과를 result.html에 전달하여 시각화\n","\n","에러\n","- 이미지가 없는 경우 : 400\n","- 분석 실패한 경우 : 500"],"metadata":{"id":"LHVtOfPdA6N0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1rkcrnXCOGXA"},"outputs":[],"source":["# Flask 엔드포인트\n","@app.route('/', methods=['GET', 'POST'])\n","\n","# 업로드 및 결과 페이지 렌더링\n","def home():\n","    return render_template(\"upload.html\")\n","\n","@app.route(\"/result\")\n","def scalp_record():\n","    return render_template(\"result.html\")\n","\n","@app.route('/file', methods=['POST'])\n","def analyze():\n","    if 'image' not in request.files:\n","        return jsonify({\"error\": \"No image uploaded\"}), 400\n","\n","    file = request.files['image']\n","    image = Image.open(file.stream).convert('RGB')\n","    image = np.array(image)\n","    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","\n","    result = process_image(image)\n","\n","    if result is None:\n","        return jsonify({\"error\": \"Failed to process image\"}), 500\n","\n","    return render_template(\"result.html\", uploaded_image1=f\"data:image/jpeg;base64,{result['image1']}\",\n","                           uploaded_image2=f\"data:image/jpeg;base64,{result['image2']}\",\n","                           result=result)\n","\n","\n","# 서버 실행\n","if __name__ == \"__main__\":\n","    app.run(host='0.0.0.0', port=8156)\n","\n"]}]}